{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import praw\n",
    "from dask.diagnostics import ProgressBar\n",
    "from tqdm import tqdm\n",
    "import hashlib\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from shared_code.utility.schemas.pyarrow_schema import schema\n",
    "from shared_code.utility.spark.set_environ import set_azure_env\n",
    "import os\n",
    "import torch\n",
    "\n",
    "set_azure_env()\n",
    "\n",
    "from shared_code.utility.storage.azure_file_storage import AzureFileStorageAdapter\n",
    "from shared_code.utility.scripts.blip_caption import BlipCaption\n",
    "\n",
    "pbar = ProgressBar()\n",
    "pbar.register()\n",
    "\n",
    "tqdm.pandas()\n",
    "tqdm.pandas(desc=\"global\")\n",
    "\n",
    "from tqdm.dask import TqdmCallback\n",
    "cb = TqdmCallback(desc=\"global\")\n",
    "cb.register()\n",
    "\n",
    "file_system = AzureFileStorageAdapter('data').get_file_storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "extant_data = pd.read_parquet(\"data/processed_raw_data.parquet\", engine='pyarrow', filesystem=file_system, schema=schema)\n",
    "display(extant_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from pmaw import PushshiftAPI\n",
    "\n",
    "reddit: praw.Reddit = praw.Reddit(client_id='5hVavL0PIRyM_1JSvqT6UQ', client_secret='BjD2kS3WNLnJc59RKY-JJUuc_Z9-JA',\n",
    "\t\t\t\t\t\t\t\t  user_agent='script:%(bot_name)s:v%(bot_version)s (by /u/%(bot_author)s)')\n",
    "\n",
    "api: PushshiftAPI = PushshiftAPI(praw=reddit)\n",
    "start_date: int = int(datetime.strptime('2022-01-01', '%Y-%m-%d').timestamp())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def filter_by_image_post(item) -> bool:\n",
    "\treturn not (item['selftext'].__contains__('[removed]') or item['selftext'].__contains__('[deleted]') and not item[\n",
    "\t\t'url'].endswith('.jpg'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def fetch_image(x: object) -> object:\n",
    "\ttry:\n",
    "\t\turl = x['original_url']\n",
    "\t\tsubreddit = x['subreddit']\n",
    "\t\tresponse = requests.get(url)\n",
    "\t\tmd5 = hashlib.md5(response.content).hexdigest()\n",
    "\t\tout_path = f\"D:\\\\data\\\\images\\\\{subreddit}\\\\{md5}.jpg\"\n",
    "\t\tif os.path.exists(out_path):\n",
    "\t\t\treturn out_path\n",
    "\t\tif md5 != \"f17b01901c752c1bb04928131d1661af\" or md5 != \"d835884373f4d6c8f24742ceabe74946\" or md5 in list(\n",
    "\t\t\t\textant_data['hash']):\n",
    "\t\t\traw_image = Image.open(BytesIO(response.content))\n",
    "\t\t\traw_image.save(out_path)\n",
    "\t\t\traw_image.close()\n",
    "\t\t\treturn out_path\n",
    "\t\telse:\n",
    "\t\t\treturn \"\"\n",
    "\texcept Exception as e:\n",
    "\t\treturn \"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def make_thumbnail(x: object) -> str:\n",
    "\timage_path = x['path']\n",
    "\tmd5 = x['hash']\n",
    "\tsubreddit = x['subreddit']\n",
    "\tout_path = f\"D:\\\\data\\\\images\\\\{subreddit}\\\\thumbnail\\\\{md5}.jpg\"\n",
    "\tif not os.path.exists(image_path):\n",
    "\t\treturn \"\"\n",
    "\tif os.path.exists(out_path):\n",
    "\t\treturn out_path\n",
    "\timg = Image.open(image_path)\n",
    "\ttry:\n",
    "\t\tcopied_image = img.copy()\n",
    "\t\tresult_copy = copied_image.resize((512, 512))\n",
    "\t\tresult_copy.save(out_path)\n",
    "\t\tresult_copy.close()\n",
    "\t\timg.close()\n",
    "\t\treturn out_path\n",
    "\texcept Exception as e:\n",
    "\t\tprint(e)\n",
    "\t\treturn \"\"\n",
    "\tfinally:\n",
    "\t\timg.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def exists(x: object) -> bool:\n",
    "\ttry:\n",
    "\t\timage_path = os.path.exists(x['path'])\n",
    "\t\tthumbnail_path = os.path.exists(x['thumbnail_path'])\n",
    "\t\treturn image_path and thumbnail_path\n",
    "\texcept Exception as e:\n",
    "\t\tprint(e)\n",
    "\t\treturn False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def split_hash(x: object) -> str:\n",
    "\ttry:\n",
    "\t\tname = x['image_name']\n",
    "\t\treturn name.split('.')[0]\n",
    "\texcept Exception as e:\n",
    "\t\tprint(e)\n",
    "\t\treturn \"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def caption_image(x: object, blip_captioning: BlipCaption) -> str:\n",
    "\ttry:\n",
    "\t\tpath = x['path']\n",
    "\t\texists_image = bool(x['exists'])\n",
    "\t\tresulting_caption = x['caption']\n",
    "\n",
    "\t\tif not os.path.exists(path):\n",
    "\t\t\treturn \"\"\n",
    "\n",
    "\t\tif not exists_image:\n",
    "\t\t\treturn \"\"\n",
    "\n",
    "\t\tif len(resulting_caption) > 5:\n",
    "\t\t\treturn resulting_caption\n",
    "\n",
    "\t\tresulting_caption = blip_captioning.caption_image(path)\n",
    "\t\treturn resulting_caption\n",
    "\n",
    "\texcept Exception as e:\n",
    "\t\treturn \"\"\n",
    "\tfinally:\n",
    "\t\tpass"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_image_name(x: object) -> str:\n",
    "\ttry:\n",
    "\t\tpath = x['path']\n",
    "\t\tif path == \"\":\n",
    "\t\t\treturn \"\"\n",
    "\t\treturn os.path.basename(path)\n",
    "\texcept Exception as e:\n",
    "\t\tprint(e)\n",
    "\t\treturn \"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "subs = [\n",
    "\t# \"oldladiesbakingpies\",\n",
    "\t# \t\"fatsquirrelhate\",\n",
    "\t# \t\"trippinthroughtime\",\n",
    "\t# \t\"spaceporn\",\n",
    "\t# \t\"memes\",\n",
    "\t# \t\"EarthPorn\",\n",
    "\t# \t\"CityPorn\",\n",
    "\t\t\"sfwpetite\",\n",
    "\t\t# \"SFWNextDoorGirls\",\n",
    "\t\t# \"SFWRedheads\",\n",
    "\t\t# \"RealGirls_SFW\",\n",
    "\t\t# \"amihot\",\n",
    "\t\t# \"SFWcurvy\"\n",
    "]\n",
    "\n",
    "all_posts = []\n",
    "\n",
    "for item in subs:\n",
    "\tposts = api.search_submissions(subreddit=item, limit=1000, filter_fn=filter_by_image_post, mem_safe=True, cache_dir='D:\\\\cache\\\\')\n",
    "\t[all_posts.append(post) for post in posts]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "df = pd.DataFrame([item for item in all_posts])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "display(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "initial = pd.DataFrame({}, columns=schema.names)\n",
    "initial['id'] = df['id']\n",
    "initial['subreddit'] = df['subreddit']\n",
    "initial['author'] = df['author']\n",
    "initial['title'] = df['title']\n",
    "initial['caption'] = \"\"\n",
    "initial['hash'] = \"\"\n",
    "initial['permalink'] = df['permalink']\n",
    "initial['original_url'] = df['url']\n",
    "initial['image_name'] = \"\"\n",
    "initial['path'] = \"\"\n",
    "initial['thumbnail_path'] = \"\"\n",
    "initial['exists'] = False\n",
    "initial['curated'] = False\n",
    "\n",
    "filtered_initial = initial.where(initial['original_url'].str.endswith('.jpg')).dropna(how='all').reset_index().drop('index', axis=1)\n",
    "\n",
    "display(filtered_initial)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "new_entries = filtered_initial.where(~filtered_initial['id'].isin(extant_data['id'])).dropna(how='all').reset_index().drop('index', axis=1)\n",
    "\n",
    "display(new_entries)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "new_entries_1 = new_entries.copy()\n",
    "\n",
    "with ProgressBar():\n",
    "\tnew_entries_1['path'] = new_entries_1.progress_apply(lambda x: fetch_image(x), axis=1)\n",
    "with ProgressBar():\n",
    "\tnew_entries_1['image_name'] = new_entries_1.progress_apply(lambda x: get_image_name(x), axis=1)\n",
    "with ProgressBar():\n",
    "\tnew_entries_1['hash'] = new_entries_1.progress_apply(lambda x: split_hash(x), axis=1)\n",
    "\n",
    "display(new_entries_1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "new_entries_2 = new_entries_1.copy()\n",
    "\n",
    "with ProgressBar():\n",
    "\tnew_entries_2['thumbnail_path'] = new_entries_2.progress_apply(lambda x: make_thumbnail(x), axis=1)\n",
    "with ProgressBar():\n",
    "\tnew_entries_2['exists'] = new_entries_2.progress_apply(lambda x: exists(x), axis=1)\n",
    "\n",
    "display(new_entries_2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "blip = BlipCaption(1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "new_entries_final = new_entries_2.copy()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "with pbar:\n",
    "\tddf = dd.from_pandas(new_entries_final, npartitions=6)\n",
    "\tnew_entries_final['caption'] = ddf.apply(lambda x: caption_image(x, blip), meta=('str', object), axis=1).compute()\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "display(new_entries_final)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "writeable_entries = new_entries_final\\\n",
    "\t.where(~new_entries_final['id'].isin(extant_data['id']))\\\n",
    "\t.dropna(how='all')\\\n",
    "\t.reset_index()\\\n",
    "\t.drop('index', axis=1)\n",
    "\n",
    "combined_result = pd.concat([extant_data, writeable_entries])\n",
    "\n",
    "display(combined_result)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "combined_result.reindex()\n",
    "combined_result.to_csv('processed_raw_data.csv', index=False)\n",
    "f = AzureFileStorageAdapter('data').get_file_storage()\n",
    "f.put('processed_raw_data.csv','data/processed_raw_data.csv', overwrite=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "final = pd.read_csv(f.open('data/processed_raw_data.csv'))\n",
    "final.to_parquet(\"data/processed_raw_data.parquet\", engine='pyarrow', filesystem=file_system, schema=schema)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "final = pd.read_parquet(\"data/processed_raw_data.parquet\", engine='pyarrow', filesystem=file_system)\n",
    "display(final)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
