{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas\n",
    "\n",
    "import dask.dataframe as dd\n",
    "\n",
    "from shared_code.utility.spark.set_environ import set_azure_env\n",
    "\n",
    "set_azure_env()\n",
    "\n",
    "from shared_code.utility.storage.table import TableAdapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tqdm.dask import TqdmCallback\n",
    "cb = TqdmCallback(desc=\"global\")\n",
    "cb.register()\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas(desc=\"global\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "class InnerProgressBar(tqdm):\n",
    "\tdef __init__(self, total, desc):\n",
    "\t\tsuper().__init__(desc=desc)\n",
    "\t\tself.total = total\n",
    "\t\tself.current = 0\n",
    "\n",
    "\tdef update_to(self):\n",
    "\t\tself.update(self.current)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "table_name = \"training\"\n",
    "\n",
    "table_adapter: TableAdapter = TableAdapter()\n",
    "\n",
    "data_path = \"/data/parquet/\"\n",
    "\n",
    "parquet_raw_data_path = data_path + \"raw_data.parquet\"\n",
    "\n",
    "parquet_process_data_path = data_path + \"processed_data.parquet\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "os.makedirs(data_path, exist_ok=True)\n",
    "\n",
    "print(f\"Data Path:\\t{data_path}\\n\\nExists:\\t{os.path.exists(data_path)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pandas_df = None\n",
    "if os.path.exists(\"foo\"):\n",
    "\tprint(\"Loading from parquet\")\n",
    "\tpandas_df = pandas.read_parquet(parquet_raw_data_path)\n",
    "\n",
    "\n",
    "else:\n",
    "\tprint(\"Loading from table\")\n",
    "\traw_data = table_adapter.get_all_entities(table_name)\n",
    "\tpandas_df = pandas.DataFrame(list(raw_data))\n",
    "\tprint(f\"Saving to parquet {parquet_process_data_path}\")\n",
    "\tpandas_df.to_parquet(parquet_raw_data_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(f\"Initial Dataframe Shape:\\t{pandas_df.shape}\")\n",
    "\n",
    "display(pandas_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Normalizing Dataframe For Processing\")\n",
    "\n",
    "subreddit = pandas_df[\"subreddit\"]\n",
    "image = pandas_df[\"image_name\"]\n",
    "text = pandas_df[\"text\"]\n",
    "hash_value = pandas_df[\"hash\"]\n",
    "original_caption = pandas_df[\"caption\"]\n",
    "thumbnail_caption = pandas_df[\"updated_caption\"]\n",
    "comment_id = pandas_df[\"id\"]\n",
    "all_normalized_frame = pandas.DataFrame(\n",
    "\t{\n",
    "\t\t\"subreddit\": subreddit,\n",
    "\t\t\"file_name\": image,\n",
    "\t\t\"text\": text,\n",
    "\t\t\"original_caption\": original_caption,\n",
    "\t\t\"thumbnail_path\": pandas_df.apply(lambda x: f\"D:\\\\data\\\\images\\\\{x['subreddit']}\\\\thumbnail\\\\{x['image_name']}\", axis=1),\n",
    "\t\t\"thumbnail_caption\": thumbnail_caption,\n",
    "\t\t\"thumbnail_exists\": pandas_df.apply(lambda x: os.path.exists(f\"D:\\\\data\\\\images\\\\{x['subreddit']}\\\\thumbnail\\\\{x['image_name']}\"), axis=1),\n",
    "\t\t\"original_image\": pandas_df.apply(lambda x: f\"D:\\\\data\\\\images\\\\{x['subreddit']}\\\\{x['image_name']}\", axis=1),\n",
    "\t\t\"original_image_exists\": pandas_df.apply(lambda x: os.path.exists(f\"D:\\\\data\\\\images\\\\{x['subreddit']}\\\\thumbnail\\\\{x['image_name']}\"), axis=1),\n",
    "\t\t\"hash\": hash_value,\n",
    "\t\t\"id\": comment_id\n",
    "\t}\n",
    ")\n",
    "display(f\"Normalized Dataframe Shape:\\t{all_normalized_frame.shape}\")\n",
    "display(f\"Saving to parquet {parquet_process_data_path}\")\n",
    "all_normalized_frame.to_parquet(parquet_process_data_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(f\"Reading from parquet {parquet_process_data_path}\")\n",
    "all_normalized_frame = pandas.read_parquet(parquet_process_data_path)\n",
    "display(all_normalized_frame)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(\"Filtering Subreddits with Images\")\n",
    "filtered_on_exist = all_normalized_frame[(all_normalized_frame[\"thumbnail_exists\"] == True) & (all_normalized_frame[\"original_image_exists\"] == True)]\n",
    "\n",
    "total_images_display = filtered_on_exist.groupby(\"subreddit\").size().reset_index(name=\"count\")\n",
    "display(total_images_display.sort_values(\"count\", ascending=False))\n",
    "display(f\"Total Records {total_images_display['count'].sum()}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(\"Data With Known Images\")\n",
    "display(filtered_on_exist)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from shared_code.utility.scripts import blip_caption\n",
    "blip_caption = blip_caption.BlipCaption(1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def caption_image(image_path) -> str:\n",
    "\ttry:\n",
    "\t\tcaption = blip_caption.caption_image(image_path)\n",
    "\t\treturn caption\n",
    "\texcept Exception as e:\n",
    "\t\tprint(f\":: Error in caption_image: {e}\")\n",
    "\t\treturn \"bruh\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def wrapper_for_captions(row: object) -> str:\n",
    "\tbruh = \"bruh\"\n",
    "\ttry:\n",
    "\t\tcaption = row[\"original_caption\"]\n",
    "\t\timage_path = row[\"original_image\"]\n",
    "\t\tfoo = row.__dict__['_name']  # Fucking silly\n",
    "\t\tprogress.update()\n",
    "\n",
    "\t\tif caption and len(caption) > 5:\n",
    "\t\t\treturn caption\n",
    "\t\telse:\n",
    "\t\t\treturn blip_caption.caption_image(image_path)\n",
    "\texcept Exception as e:\n",
    "\t\tprint(e)\n",
    "\t\treturn bruh"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_tokens(row: object):\n",
    "\tbruh = \"bruh\"\n",
    "\ttry:\n",
    "\t\tcaption = row[\"original_caption\"]\n",
    "\t\tprogress.update()\n",
    "\t\ttokens = blip_caption.get_nlk_tokens(caption)\n",
    "\t\treturn tokens\n",
    "\texcept Exception as e:\n",
    "\t\tprint(e)\n",
    "\t\treturn bruh"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "temp = filtered_on_exist.copy()\n",
    "ddf = dd.from_pandas(temp, npartitions=12)\n",
    "display(temp)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "progress: tqdm = InnerProgressBar(len(temp), \"Captioning-Primary-Images\")\n",
    "display(f\"Total Images: {progress.total}\")\n",
    "temp['new_column'] = ddf.apply(lambda x: wrapper_for_captions(x), axis=1, meta=('str', object)).compute()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(\"=== Before Drop ===\")\n",
    "display(temp)\n",
    "temp.rename(columns={\"original_caption\": \"original_caption_old\"}, inplace=True)\n",
    "temp.rename(columns={\"new_column\": \"original_caption\"}, inplace=True)\n",
    "temp.drop(columns=[\"original_caption_old\"], inplace=True)\n",
    "display(\"=== After Drop ===\")\n",
    "display(temp)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(f\"Saving to parquet {parquet_process_data_path}\")\n",
    "temp.to_parquet(parquet_process_data_path)\n",
    "del temp"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(f\"Reading from parquet {parquet_process_data_path} with Updated Primary Captions\")\n",
    "processed_with_captions = pandas.read_parquet(parquet_process_data_path)\n",
    "display(processed_with_captions)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "temp = processed_with_captions.copy()\n",
    "ddf = dd.from_pandas(temp, npartitions=6)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "progress = InnerProgressBar(len(temp), \"Captioning-Tokens-For-Image\")\n",
    "display(f\"Total Images: {progress.total}\")\n",
    "temp['new_column'] = ddf.apply(lambda x: create_tokens(x), axis=1, meta=('str', object)).compute()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(\"=== Before Drop ===\")\n",
    "display(temp)\n",
    "temp.rename(columns={\"thumbnail_caption\": \"thumbnail_caption_old\"}, inplace=True)\n",
    "temp.rename(columns={\"new_column\": \"thumbnail_caption\"}, inplace=True)\n",
    "temp.drop(columns=[\"thumbnail_caption_old\"], inplace=True)\n",
    "display(\"=== After Drop ===\")\n",
    "display(temp)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(f\"Saving to parquet {parquet_process_data_path} with Updated Thumbnail Captions\")\n",
    "temp.to_parquet(parquet_process_data_path)\n",
    "del temp"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(f\"Reading from parquet {parquet_process_data_path} with Updated Thumbnail Captions\")\n",
    "processed_with_captions_more = pandas.read_parquet(parquet_process_data_path)\n",
    "display(processed_with_captions_more)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(\"Filtering Subreddits with Images By original_caption\")\n",
    "filtered_captions = processed_with_captions_more[\n",
    "\t(processed_with_captions_more[\"original_caption\"] != \"bruh\") &\n",
    "\t(~processed_with_captions_more[\"original_caption\"].isna() | ~ processed_with_captions_more[\n",
    "\t\t\"original_caption\"].isnull())\n",
    "\t]\n",
    "\n",
    "filtered_captions_display = filtered_captions.groupby(\"subreddit\").size().reset_index(name=\"count\")\n",
    "\n",
    "display(filtered_captions_display.sort_values(\"count\", ascending=False))\n",
    "display(f\"Total Records {filtered_captions_display['count'].sum()}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(\"Filtering Subreddits with Images By thumbnail_caption\")\n",
    "filtered_captions_by_thumbnail = filtered_captions[\n",
    "\t(processed_with_captions_more[\"thumbnail_caption\"] != \"bruh\") &\n",
    "\t(~processed_with_captions_more[\"thumbnail_caption\"].isna() | ~ processed_with_captions_more[\n",
    "\t\t\"thumbnail_caption\"].isnull())\n",
    "\t]\n",
    "filtered_captions_by_thumbnail_display = filtered_captions_by_thumbnail.groupby(\"subreddit\").size().reset_index(name=\"count\")\n",
    "display(filtered_captions_by_thumbnail_display.sort_values(\"count\", ascending=False))\n",
    "display(f\"Total Records {filtered_captions_by_thumbnail_display['count'].sum()}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(\"Updating Cloud Storage With Filtered Captioned Images\")\n",
    "def update_cloud(row):\n",
    "\ttry:\n",
    "\t\t_table_adapter = TableAdapter()\n",
    "\t\tpartition_key = \"training\"\n",
    "\t\trow_key = row[\"id\"]\n",
    "\t\tcaption = row[\"original_caption\"]\n",
    "\t\tupdated_caption = row[\"thumbnail_caption\"]\n",
    "\t\tentity = _table_adapter.get_entity(\"training\", partition_key, row_key)\n",
    "\t\tentity[\"caption\"] = caption\n",
    "\t\tentity[\"updated_caption\"] = updated_caption\n",
    "\t\t_table_adapter.upsert_entity_to_table(\"training\", entity)\n",
    "\t\tprogress.update()\n",
    "\t\treturn \"bruh\"\n",
    "\texcept Exception as e:\n",
    "\t\tprint(e)\n",
    "\t\treturn \"bruh\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "upload to cloud:  11%|█▏        | 892/7888 [03:39<41:45,  2.79it/s]\u001B[A\n",
      "upload to cloud:  11%|█▏        | 893/7888 [03:39<42:56,  2.72it/s]\u001B[A\n",
      "upload to cloud:  11%|█▏        | 896/7888 [03:40<40:11,  2.90it/s]\u001B[A\n",
      "upload to cloud:  11%|█▏        | 898/7888 [03:40<53:00,  2.20it/s]\u001B[A\n",
      "upload to cloud:  11%|█▏        | 899/7888 [03:40<1:09:11,  1.68it/s]\u001B[A\n",
      "upload to cloud:  11%|█▏        | 899/7888 [03:40<1:09:11,  1.68it/s]\u001B[A\n",
      "upload to cloud:  11%|█▏        | 900/7888 [03:40<1:31:57,  1.27it/s]\u001B[A"
     ]
    },
    {
     "data": {
      "text/plain": "                subreddit          file_name  \\\n0                CityPorn  4emw5uldib9a1.jpg   \n3                AmIhotAF  4xyb1vgbjb9a1.jpg   \n4               greentext  3mewbe0wjb9a1.jpg   \n5               spaceporn  7s5aafaqkb9a1.jpg   \n7               spaceporn  abojw7lqlb9a1.jpg   \n...                   ...                ...   \n11724           spaceporn  abwhhq0w8b9a1.jpg   \n11725           spaceporn  7hzipg1bab9a1.jpg   \n11726           greentext        bgho6WK.jpg   \n11728  trippinthroughtime        arCpzQ0.jpg   \n11730     HotGirlNextDoor  p6yewrl7eb9a1.jpg   \n\n                                                    text  \\\n0                                    New York in the fog   \n3                         Just looking for entertainment   \n4                                    Anon wants Elon cut   \n5                          Northern Lights above Lofoten   \n7                                          Viking Lights   \n...                                                  ...   \n11724           Polaris to Cassiopeia on a cloudy night.   \n11725  The hunt for habitable ocean worlds beyond our...   \n11726                        Anon does a little trolling   \n11728         He didn't shed light on the topic I guess.   \n11730                                             (IKTR)   \n\n                                          thumbnail_path  thumbnail_exists  \\\n0      D:\\data\\images\\CityPorn\\thumbnail\\4emw5uldib9a...              True   \n3      D:\\data\\images\\AmIhotAF\\thumbnail\\4xyb1vgbjb9a...              True   \n4      D:\\data\\images\\greentext\\thumbnail\\3mewbe0wjb9...              True   \n5      D:\\data\\images\\spaceporn\\thumbnail\\7s5aafaqkb9...              True   \n7      D:\\data\\images\\spaceporn\\thumbnail\\abojw7lqlb9...              True   \n...                                                  ...               ...   \n11724  D:\\data\\images\\spaceporn\\thumbnail\\abwhhq0w8b9...              True   \n11725  D:\\data\\images\\spaceporn\\thumbnail\\7hzipg1bab9...              True   \n11726     D:\\data\\images\\greentext\\thumbnail\\bgho6WK.jpg              True   \n11728  D:\\data\\images\\trippinthroughtime\\thumbnail\\ar...              True   \n11730  D:\\data\\images\\HotGirlNextDoor\\thumbnail\\p6yew...              True   \n\n                                         original_image  \\\n0             D:\\data\\images\\CityPorn\\4emw5uldib9a1.jpg   \n3             D:\\data\\images\\AmIhotAF\\4xyb1vgbjb9a1.jpg   \n4            D:\\data\\images\\greentext\\3mewbe0wjb9a1.jpg   \n5            D:\\data\\images\\spaceporn\\7s5aafaqkb9a1.jpg   \n7            D:\\data\\images\\spaceporn\\abojw7lqlb9a1.jpg   \n...                                                 ...   \n11724        D:\\data\\images\\spaceporn\\abwhhq0w8b9a1.jpg   \n11725        D:\\data\\images\\spaceporn\\7hzipg1bab9a1.jpg   \n11726              D:\\data\\images\\greentext\\bgho6WK.jpg   \n11728     D:\\data\\images\\trippinthroughtime\\arCpzQ0.jpg   \n11730  D:\\data\\images\\HotGirlNextDoor\\p6yewrl7eb9a1.jpg   \n\n       original_image_exists                              hash       id  \\\n0                       True  7a8d96e378c15c8ab8440ac311f12c11  1000cej   \n3                       True  e554c1ed7ffa2740436ac082068b2824  1000glf   \n4                       True  1dec3dabb5e46cde01855d06089c287a  1000j1n   \n5                       True  2c39ce1290fba541abd0b004b09da6b2  1000mjs   \n7                       True  0f72de47c69ff50eca5fa3990215f4ac  1000qpd   \n...                      ...                               ...      ...   \n11724                   True  f5973637fc56360c15818ba0ca1f7ffa   zzz6dp   \n11725                   True  5b22bea7582229c1f9b992176a2ca2c6   zzzcn5   \n11726                   True  df666b8b2ad543c77b3fdba89becda1a   zzzeoi   \n11728                   True  5007b937974ae333022c0c91b795ca09   zzzlbf   \n11730                   True  94dea288ddffb51eb1a786d469b59374   zzzu28   \n\n                                        original_caption  \\\n0      cars are parked on the side of the road in the...   \n3      blonde woman with blonde hair and tattoos on h...   \n4      a man with a beard and a beard sitting in fron...   \n5      a view of a view of a large green and purple a...   \n7      a scene of a boat is sitting on the shore of a...   \n...                                                  ...   \n11724     starrdust sky with a few stars and a few stars   \n11725  a picture taken from the earth's surface of th...   \n11726  a screenshote of a text message from a man who...   \n11728    a man in a red dress and a woman in a red dress   \n11730  blonde woman in black bikini top and black bik...   \n\n                                       thumbnail_caption  \n0      \"cars|NNS\",\"are|VBP\",\"parked|VBN\",\"on|IN\",\"the...  \n3      \"blonde|NNS\",\"woman|NN\",\"with|IN\",\"hair|NN\",\"a...  \n4      \"man|NN\",\"with|IN\",\"beard|NN\",\"and|CC\",\"sittin...  \n5      \"view|NN\",\"of|IN\",\"large|JJ\",\"green|JJ\",\"and|C...  \n7      \"scene|NN\",\"of|IN\",\"boat|NN\",\"is|VBZ\",\"sitting...  \n...                                                  ...  \n11724  \"starrdust|NN\",\"sky|NN\",\"with|IN\",\"few|JJ\",\"st...  \n11725  \"picture|NN\",\"taken|VBN\",\"from|IN\",\"the|DT\",\"e...  \n11726  \"screenshote|NN\",\"of|IN\",\"text|JJ\",\"message|NN...  \n11728  \"man|NN\",\"in|IN\",\"red|JJ\",\"dress|NN\",\"and|CC\",...  \n11730  \"blonde|NN\",\"woman|NN\",\"in|IN\",\"black|JJ\",\"bik...  \n\n[7888 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subreddit</th>\n      <th>file_name</th>\n      <th>text</th>\n      <th>thumbnail_path</th>\n      <th>thumbnail_exists</th>\n      <th>original_image</th>\n      <th>original_image_exists</th>\n      <th>hash</th>\n      <th>id</th>\n      <th>original_caption</th>\n      <th>thumbnail_caption</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>CityPorn</td>\n      <td>4emw5uldib9a1.jpg</td>\n      <td>New York in the fog</td>\n      <td>D:\\data\\images\\CityPorn\\thumbnail\\4emw5uldib9a...</td>\n      <td>True</td>\n      <td>D:\\data\\images\\CityPorn\\4emw5uldib9a1.jpg</td>\n      <td>True</td>\n      <td>7a8d96e378c15c8ab8440ac311f12c11</td>\n      <td>1000cej</td>\n      <td>cars are parked on the side of the road in the...</td>\n      <td>\"cars|NNS\",\"are|VBP\",\"parked|VBN\",\"on|IN\",\"the...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AmIhotAF</td>\n      <td>4xyb1vgbjb9a1.jpg</td>\n      <td>Just looking for entertainment</td>\n      <td>D:\\data\\images\\AmIhotAF\\thumbnail\\4xyb1vgbjb9a...</td>\n      <td>True</td>\n      <td>D:\\data\\images\\AmIhotAF\\4xyb1vgbjb9a1.jpg</td>\n      <td>True</td>\n      <td>e554c1ed7ffa2740436ac082068b2824</td>\n      <td>1000glf</td>\n      <td>blonde woman with blonde hair and tattoos on h...</td>\n      <td>\"blonde|NNS\",\"woman|NN\",\"with|IN\",\"hair|NN\",\"a...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>greentext</td>\n      <td>3mewbe0wjb9a1.jpg</td>\n      <td>Anon wants Elon cut</td>\n      <td>D:\\data\\images\\greentext\\thumbnail\\3mewbe0wjb9...</td>\n      <td>True</td>\n      <td>D:\\data\\images\\greentext\\3mewbe0wjb9a1.jpg</td>\n      <td>True</td>\n      <td>1dec3dabb5e46cde01855d06089c287a</td>\n      <td>1000j1n</td>\n      <td>a man with a beard and a beard sitting in fron...</td>\n      <td>\"man|NN\",\"with|IN\",\"beard|NN\",\"and|CC\",\"sittin...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>spaceporn</td>\n      <td>7s5aafaqkb9a1.jpg</td>\n      <td>Northern Lights above Lofoten</td>\n      <td>D:\\data\\images\\spaceporn\\thumbnail\\7s5aafaqkb9...</td>\n      <td>True</td>\n      <td>D:\\data\\images\\spaceporn\\7s5aafaqkb9a1.jpg</td>\n      <td>True</td>\n      <td>2c39ce1290fba541abd0b004b09da6b2</td>\n      <td>1000mjs</td>\n      <td>a view of a view of a large green and purple a...</td>\n      <td>\"view|NN\",\"of|IN\",\"large|JJ\",\"green|JJ\",\"and|C...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>spaceporn</td>\n      <td>abojw7lqlb9a1.jpg</td>\n      <td>Viking Lights</td>\n      <td>D:\\data\\images\\spaceporn\\thumbnail\\abojw7lqlb9...</td>\n      <td>True</td>\n      <td>D:\\data\\images\\spaceporn\\abojw7lqlb9a1.jpg</td>\n      <td>True</td>\n      <td>0f72de47c69ff50eca5fa3990215f4ac</td>\n      <td>1000qpd</td>\n      <td>a scene of a boat is sitting on the shore of a...</td>\n      <td>\"scene|NN\",\"of|IN\",\"boat|NN\",\"is|VBZ\",\"sitting...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>11724</th>\n      <td>spaceporn</td>\n      <td>abwhhq0w8b9a1.jpg</td>\n      <td>Polaris to Cassiopeia on a cloudy night.</td>\n      <td>D:\\data\\images\\spaceporn\\thumbnail\\abwhhq0w8b9...</td>\n      <td>True</td>\n      <td>D:\\data\\images\\spaceporn\\abwhhq0w8b9a1.jpg</td>\n      <td>True</td>\n      <td>f5973637fc56360c15818ba0ca1f7ffa</td>\n      <td>zzz6dp</td>\n      <td>starrdust sky with a few stars and a few stars</td>\n      <td>\"starrdust|NN\",\"sky|NN\",\"with|IN\",\"few|JJ\",\"st...</td>\n    </tr>\n    <tr>\n      <th>11725</th>\n      <td>spaceporn</td>\n      <td>7hzipg1bab9a1.jpg</td>\n      <td>The hunt for habitable ocean worlds beyond our...</td>\n      <td>D:\\data\\images\\spaceporn\\thumbnail\\7hzipg1bab9...</td>\n      <td>True</td>\n      <td>D:\\data\\images\\spaceporn\\7hzipg1bab9a1.jpg</td>\n      <td>True</td>\n      <td>5b22bea7582229c1f9b992176a2ca2c6</td>\n      <td>zzzcn5</td>\n      <td>a picture taken from the earth's surface of th...</td>\n      <td>\"picture|NN\",\"taken|VBN\",\"from|IN\",\"the|DT\",\"e...</td>\n    </tr>\n    <tr>\n      <th>11726</th>\n      <td>greentext</td>\n      <td>bgho6WK.jpg</td>\n      <td>Anon does a little trolling</td>\n      <td>D:\\data\\images\\greentext\\thumbnail\\bgho6WK.jpg</td>\n      <td>True</td>\n      <td>D:\\data\\images\\greentext\\bgho6WK.jpg</td>\n      <td>True</td>\n      <td>df666b8b2ad543c77b3fdba89becda1a</td>\n      <td>zzzeoi</td>\n      <td>a screenshote of a text message from a man who...</td>\n      <td>\"screenshote|NN\",\"of|IN\",\"text|JJ\",\"message|NN...</td>\n    </tr>\n    <tr>\n      <th>11728</th>\n      <td>trippinthroughtime</td>\n      <td>arCpzQ0.jpg</td>\n      <td>He didn't shed light on the topic I guess.</td>\n      <td>D:\\data\\images\\trippinthroughtime\\thumbnail\\ar...</td>\n      <td>True</td>\n      <td>D:\\data\\images\\trippinthroughtime\\arCpzQ0.jpg</td>\n      <td>True</td>\n      <td>5007b937974ae333022c0c91b795ca09</td>\n      <td>zzzlbf</td>\n      <td>a man in a red dress and a woman in a red dress</td>\n      <td>\"man|NN\",\"in|IN\",\"red|JJ\",\"dress|NN\",\"and|CC\",...</td>\n    </tr>\n    <tr>\n      <th>11730</th>\n      <td>HotGirlNextDoor</td>\n      <td>p6yewrl7eb9a1.jpg</td>\n      <td>(IKTR)</td>\n      <td>D:\\data\\images\\HotGirlNextDoor\\thumbnail\\p6yew...</td>\n      <td>True</td>\n      <td>D:\\data\\images\\HotGirlNextDoor\\p6yewrl7eb9a1.jpg</td>\n      <td>True</td>\n      <td>94dea288ddffb51eb1a786d469b59374</td>\n      <td>zzzu28</td>\n      <td>blonde woman in black bikini top and black bik...</td>\n      <td>\"blonde|NN\",\"woman|NN\",\"in|IN\",\"black|JJ\",\"bik...</td>\n    </tr>\n  </tbody>\n</table>\n<p>7888 rows × 11 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "upload to cloud:  11%|█▏        | 900/7888 [03:41<1:31:57,  1.27it/s]\u001B[A\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "temp = processed_with_captions_more.copy()\n",
    "temp['foo'] = temp.apply(lambda x: \",\".join([json.dumps(\"|\".join([f for f in item.tolist()])) for item in x['thumbnail_caption'].tolist()]), axis=1)\n",
    "temp.rename(columns={\"thumbnail_caption\": \"thumbnail_caption_old\"}, inplace=True)\n",
    "temp.rename(columns={\"foo\": \"thumbnail_caption\"}, inplace=True)\n",
    "temp.drop(columns=[\"thumbnail_caption_old\"], inplace=True)\n",
    "display(temp)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[A\n",
      "upload to cloud:  15%|█▍        | 1168/7888 [03:56<26:50,  4.17it/s]\u001B[A\n",
      "upload to cloud:  15%|█▍        | 1169/7888 [03:56<28:48,  3.89it/s]\u001B[A\n",
      "upload to cloud:  15%|█▍        | 1170/7888 [03:56<24:09,  4.63it/s]\u001B[A\n",
      "upload to cloud:  15%|█▍        | 1170/7888 [03:56<24:09,  4.63it/s]\u001B[A\n",
      "upload to cloud:  15%|█▍        | 1170/7888 [03:56<24:09,  4.63it/s]\u001B[A\n",
      "upload to cloud:  15%|█▍        | 1172/7888 [03:56<31:11,  3.59it/s]\u001B[A\n",
      "upload to cloud:  15%|█▍        | 1175/7888 [03:56<16:48,  6.66it/s]\u001B[A\n",
      "upload to cloud:  15%|█▍        | 1176/7888 [03:56<20:38,  5.42it/s]\u001B[A\n",
      "upload to cloud:  15%|█▍        | 1177/7888 [03:56<22:02,  5.07it/s]\u001B[A\n",
      "upload to cloud:  15%|█▍        | 1177/7888 [03:56<22:02,  5.07it/s]\u001B[A\n",
      "upload to cloud:  15%|█▍        | 1178/7888 [03:56<23:25,  4.77it/s]\u001B[A\n",
      "upload to cloud:  15%|█▍        | 1179/7888 [03:56<24:52,  4.50it/s]\u001B[A\n",
      "upload to cloud: 0it [00:00, ?it/s]180/7888 [03:56<28:14,  3.96it/s]\u001B[A\n",
      "upload to cloud:  15%|█▍        | 1181/7888 [03:56<25:10,  4.44it/s]\u001B[A\n",
      "upload to cloud:  15%|█▍        | 1181/7888 [03:57<25:10,  4.44it/s]\u001B[A\n",
      "upload to cloud:  15%|█▍        | 1181/7888 [03:57<25:10,  4.44it/s]\u001B[A\n",
      "upload to cloud:  15%|█▍        | 1181/7888 [03:57<25:10,  4.44it/s]\u001B[A\n",
      "upload to cloud:  15%|█▍        | 1181/7888 [03:57<22:28,  4.97it/s]\u001B[A\n",
      "upload to cloud:   0%|          | 9/7888 [00:00<10:00, 13.11it/s]"
     ]
    },
    {
     "data": {
      "text/plain": "global:   0%|          | 0/12 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fb6aeae352674c759018ee7e160728d7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "upload to cloud: 14595it [11:33,  4.07it/s]                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process Complete: Items Updated\n"
     ]
    }
   ],
   "source": [
    "progress = InnerProgressBar(len(processed_with_captions_more), \"upload to cloud\")\n",
    "ddf = dd.from_pandas(temp, npartitions=12)\n",
    "ddf.apply(lambda x: update_cloud(x), axis=1, meta=('str', object)).compute()\n",
    "print(\"Process Complete: Items Updated\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
