{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from shared_code.utility.spark.set_environ import set_azure_env\n",
    "\n",
    "set_azure_env()\n",
    "\n",
    "from shared_code.utility.scripts.reddit_collector import RedditDataCollector\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logging.getLogger(\"azure.storage\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"diffusers\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"azure.core\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas\n",
    "\n",
    "import dask.dataframe as dd\n",
    "\n",
    "from shared_code.utility.spark.set_environ import set_azure_env\n",
    "\n",
    "set_azure_env()\n",
    "\n",
    "from shared_code.utility.storage.table import TableAdapter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tqdm.dask import TqdmCallback\n",
    "\n",
    "cb = TqdmCallback(desc=\"global\")\n",
    "cb.register()\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "tqdm.pandas(desc=\"global\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "class InnerProgressBar(tqdm):\n",
    "\tdef __init__(self, total, desc):\n",
    "\t\tsuper().__init__(desc=desc)\n",
    "\t\tself.total = total\n",
    "\t\tself.current = 0\n",
    "\n",
    "\tdef update_to(self):\n",
    "\t\tself.update(self.current)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "table_name = \"training\"\n",
    "image_out_dir = \"/data/images/\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "subreddits = \"greentext+selfies+Faces+EarthPorn+CityPorn+sfwpetite+SFWNextDoorGirls+SFWRedheads\"\n",
    "subs = subreddits.split(\"+\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def download_subreddit_images(subreddit) -> int:\n",
    "\tcollector: RedditDataCollector = RedditDataCollector(image_out_dir=image_out_dir, table_name=table_name)\n",
    "\tprogress.update()\n",
    "\ttry:\n",
    "\t\tcount = collector.download_subreddit_images(subreddit)\n",
    "\t\treturn count\n",
    "\texcept Exception as e:\n",
    "\t\tlogging.error(f\"Error downloading images for {subreddit}: {e}\")\n",
    "\t\treturn 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Starting greentext ==\n",
      "All images from greentext subreddit are downloaded\n",
      "== Starting selfies ==\n",
      "All images from selfies subreddit are downloaded\n",
      "== Starting Faces ==\n",
      "All images from Faces subreddit are downloaded\n",
      "== Starting EarthPorn ==\n",
      "All images from EarthPorn subreddit are downloaded\n",
      "== Starting CityPorn ==\n",
      "All images from CityPorn subreddit are downloaded\n",
      "== Starting sfwpetite ==\n",
      "All images from sfwpetite subreddit are downloaded\n",
      "== Starting SFWNextDoorGirls ==\n",
      "All images from SFWNextDoorGirls subreddit are downloaded\n",
      "== Starting SFWRedheads ==\n",
      "All images from SFWRedheads subreddit are downloaded\n",
      "+-----+----------------+\n",
      "|count|       subreddit|\n",
      "+-----+----------------+\n",
      "|    0|       greentext|\n",
      "|    0|         selfies|\n",
      "|    0|           Faces|\n",
      "|    0|       EarthPorn|\n",
      "|    0|        CityPorn|\n",
      "|    0|       sfwpetite|\n",
      "|    0|SFWNextDoorGirls|\n",
      "|    0|     SFWRedheads|\n",
      "+-----+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logging.getLogger(\"azure.storage\").setLevel(logging.WARNING)\n",
    "\n",
    "data = []\n",
    "\n",
    "ddf = dd.from_pandas(pandas.DataFrame(subs), npartitions=len(subs))\n",
    "\n",
    "progress = InnerProgressBar(total=len(subs), desc=\"global\")\n",
    "\n",
    "result = ddf.apply(lambda x: download_subreddit_images(x[0]), axis=1, meta=(\"count\", \"int64\")).compute()\n",
    "\n",
    "# for sub in subs:\n",
    "# \ttry:\n",
    "# \t\tnum_images_collected = collector.download_subreddit_images(sub)\n",
    "# \t\tresult = {\n",
    "# \t\t\t\"subreddit\": sub,\n",
    "# \t\t\t\"count\": num_images_collected\n",
    "# \t\t}\n",
    "# \t\tdata.append(result)\n",
    "# \texcept Exception as e:\n",
    "# \t\tlogging.error(f\"Error downloading images for {sub}: {e}\")\n",
    "# \t\tcontinue\n",
    "\n",
    "display(pandas.createDataFrame(data=data))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
