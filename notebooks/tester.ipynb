{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "model_name = \"test-3\"\n",
    "model_type = \"\"\n",
    "model_output_dir = f\"/workspaces/General/models/{model_name}\"\n",
    "try:\n",
    "\tos.mkdir(model_output_dir)\n",
    "except FileExistsError:\n",
    "\tpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\t_input_id: str = 'input_ids'\n",
    "\t_attention_mask: str = 'attention_mask'\n",
    "\n",
    "\tdef __init__(self, text_list, tokenizer, max_length, truncation=False):\n",
    "\t\tself.input_ids = []\n",
    "\t\tself.attention_mask = []\n",
    "\t\tself.labels = []\n",
    "\t\tfor text in text_list:\n",
    "\t\t\tencodings_dict = tokenizer(text, truncation=truncation, max_length=max_length)\n",
    "\t\t\tself.input_ids.append(torch.tensor(encodings_dict[self._input_id]))\n",
    "\t\t\tself.attention_mask.append(torch.tensor(encodings_dict[self._attention_mask]))\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.input_ids)\n",
    "\n",
    "\tdef __getitem__(self, index):\n",
    "\t\treturn self.input_ids[index], self.attention_mask[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionAnswer(object):\n",
    "\tdef __init__(self, question: str, answer: str):\n",
    "\t\tself.question: str = question\n",
    "\t\tself.answer: str = answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(object):\n",
    "\t__bos_token: str = '<|startoftext|>'\n",
    "\t__eos_token: str = '<|endoftext|>'\n",
    "\n",
    "\t# Non-Standard Tokens\n",
    "\t__start_of_question_token: str = '<|startofquestion|>'\n",
    "\t__end_of_question_token: str = '<|endofquestion|>'\n",
    "\t__start_of_reply_token: str = '<|startofreply|>'\n",
    "\t__end_of_reply_token: str = '<|endofreply|>'\n",
    "\n",
    "\n",
    "\t@classmethod\n",
    "\tdef create_data_line(cls, data_line: QuestionAnswer) -> str:\n",
    "\t\ttagged_text: str = cls.__bos_token\n",
    "\t\ttagged_text += cls.__start_of_question_token\n",
    "\t\ttagged_text += data_line.question\n",
    "\t\ttagged_text += cls.__end_of_question_token\n",
    "\t\ttagged_text += cls.__start_of_reply_token\n",
    "\t\ttagged_text += data_line.answer\n",
    "\t\ttagged_text += cls.__end_of_reply_token\n",
    "\t\ttagged_text += cls.__eos_token\n",
    "\n",
    "\t\treturn tagged_text\n",
    "\n",
    "\t@classmethod\n",
    "\tdef get_special_token_dict(cls) -> dict:\n",
    "\t\treturn {\n",
    "\t\t\t\"bos_token\": f\"{cls.__bos_token}\",\n",
    "\t\t\t\"eos_token\": f\"{cls.__eos_token}\",\n",
    "\t\t\t\"additional_special_tokens\": [\n",
    "\t\t\t\tf\"{cls.__bos_token}\",\n",
    "\t\t\t\tf\"{cls.__eos_token}\",\n",
    "\t\t\t\tf\"{cls.__start_of_question_token}\"\n",
    "\t\t\t\tf\"{cls.__end_of_question_token}\"\n",
    "\t\t\t\tf\"{cls.__start_of_reply_token}\"\n",
    "\t\t\t\tf\"{cls.__end_of_reply_token}\"\n",
    "\t\t\t]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lines = [\n",
    "\tQuestionAnswer(question=\"what is required to sign up a customer for ENS?\", answer=\"To enroll in the encounter notification service please ensure that your organization has executed a participation agreement with CRISP and updated your organizations Notice of Privacy Practices (NPP). Once those steps are completed the CRISP team will provide a template file for you to securely submit your patient member file to the HIE. Additionally there is a checklist that will allow you to choose what notifications you want to receive and how you want to receive them. All users can use our ENS PROMPT tool at no cost.\"),\n",
    "\tQuestionAnswer(question=\"what types of organizations participate in CRISP?\", answer=\"A Health Information Exchange, or HIE, is a way of sharing your health information among participating doctors’ offices, hospitals, care coordinators, labs, radiology centers, and other health care providers through secure, electronic means. The purpose is so that each of your participating healthcare providers can have the benefit of the most recent information available from your other participating providers when taking care of you. When you opt out of participation in the HIE, doctors and nurses will not be able to search for your health information through the HIE to use while treating you. Your physician or other treating providers will still be able to select the HIE as a way to receive your lab results, radiology reports, and other data sent directly to them that they may have previously received by fax, mail, or other electronic communications.\"),\n",
    "\tQuestionAnswer(question=\"If I don't want to share my information with CRISP can I choose to opt-out?\", answer=\"Please be advised that opting out does not preclude any participating organization that has received or accessed personal health information via the HIE prior to such opt-out, and incorporated such personal health information into its records, from retaining such information in its records. Additionally, in accordance with the law, Public health reporting, such as the reporting of infectious diseases to public health officials, will still occur through the HIE after you decide to opt out. Controlled Dangerous Substances (CDS) information, as part of the Maryland Prescription Drug Monitoring Program, will continue to be available through the HIE to licensed providers.If you choose to opt out of research only, your information will be available to your treating providers, but will be excluded from any data sets created for researchers.\"),\n",
    "\tQuestionAnswer(question=\"what is the value of becoming an affiliate of CRISP Shared Services?\", answer=\"As Maryland’s official regional Health Information Exchange, the CRISP HIE network is comprised of hundreds of connected providers, consisting of hospitals, EMRs, pharmacies, payors, health departments, and health centers.\"),\n",
    "\tQuestionAnswer(question=\"what is the CRISP Shared Services?\", answer=\"CRISP Shared Services (CSS) is a non-profit support organization that provides technology infrastructure and other core services to Health Information Exchanges (HIEs) across the US. We are different than a vendor in that each of our Member HIEs participates in the governance of the organization.\"),\n",
    "\tQuestionAnswer(question=\"what is the motivation of CRISP Shared Services?\", answer=\"Our primary motivation is to enable and support each local jurisdiction’s Healthcare community so that it can improve health outcomes for its patients. We work with local HIE leadership to implement solutions which best serve the needs of their unique communities, even if those solutions are deployed or built by external vendors.\"),\n",
    "\tQuestionAnswer(question=\"what is the mission of CRISP Shared Services?\", answer=\"Our mission is to assist member organizations in achieving economies of scale, pooling innovation efforts, and implementing best practices.\"),\n",
    "\tQuestionAnswer(question=\"What is CRISP?\", answer=\"CRISP is the State Designated Health Information Exchange (HIE) for Maryland.\"),\n",
    "\tQuestionAnswer(question=\"What does CRISP do?\", answer=\"We are a non-profit organization that facilitates the electronic transfer of clinical information between disparate health information systems.\"),\n",
    "\tQuestionAnswer(question=\"Clinical Data\", answer=\"As clinical information is created and shared with CRISP, it is made accessible in near real-time to participating health care providers through the CRISP tools. Providers have the ability to securely look up patient information through the internet. CRISP tools retrieve clinical data from participants and display it in a view-only screen at the point of care.\"),\n",
    "\tQuestionAnswer(question=\"Where is CRISP clinical data? When Is It Made Available?\", answer=\"CRISP clinical data is available through the CRISP Portal at no cost to clinical staff. As clinical information is created and shared with CRISP, it is made accessible in real-time to participating healthcare providers across institutional boundaries through the Clinical Information Service. The portal gives providers the ability to securely look up patient information via their browser. It retrieves clinical data from participants and displays it in a view-only screen at the point of care.\"),\n",
    "\tQuestionAnswer(question=\"How can I View Patient Data?\", answer=\"The Patient Care Snapshot combines critical information relevant to your role in the patient’s care. It displays data from a variety of sources to provide an at-a-glance view of the patient’s clinical history. Information is presented from a compilation of care management data alongside real-time hospital encounter feeds, up-to-date demographic information, patient to care provider attribution, and clinical summaries of care from our real-time interfaces with providers across the region.\"),\n",
    "\tQuestionAnswer(question=\"How can I View Patient Data?\", answer=\"Imaging Worklist allows users to compare images across multiple locations via the Imaging Worklist tab through CRISP’s Portal. Patient images from CRISP participating sites dating back to 01/01/2000 are available through CRISP’s Imaging Worklist as well. In addition, up to four imaging studies can be selected, viewed, and compared at the same time.\"),\n",
    "\tQuestionAnswer(question=\"How can I View Patient Data?\", answer=\"Image Exchange is an online image-sharing service that allows CRISP users to view patient diagnostic images in one central location.Currently, 50 hospitals and 9 outpatient groups across Maryland and DC are contributing images to the Image Exchange service. These images are then made available to CRISP users through our portals to facilitate greater collaboration and efficiency among healthcare providers, ultimately leading to higher quality patient care.The diagnostic images are securely stored on servers located within each connected hospital’s local environment. Images taken within the last 90 days are made available to all authorized CRISP users within seconds of collection, while deeper archives of images older than 90 days are available within minutes.CRISP offers two ways of viewing patient clinical data and images. The first option is to directly log on to the CRISP Portal, using specific user credentials. The second option is to access images via the HIE InContext platform within each respective EMR.In addition to the image access provided through Health Records and Imaging Worklist, Image Exchange participants can also request access to the following features: Transfer-to-PACS and Emergent.\"),\n",
    "\tQuestionAnswer(question=\"Is access to an Electronic Medical Record (EMR) required to participate in CRISP?\", answer=\"An EMR is not required to access CRISP or the data we provide. CRISP data is accessible through any Internet browser via the CRISP Portal.\"),\n",
    "\tQuestionAnswer(question=\"Is there a cost associated with accessing CRISP data?\", answer=\"There is no cost. Access to CRISP is free to ambulatory practices.\"),\n",
    "\tQuestionAnswer(question=\"Who do I sign up for CRISP?\", answer=\"To get started, an organization must sign a CRISP Participation agreement for single sites or an agreement for organizations with multiple sites and must update its Notice of Privacy Practices documents. If your organization has already signed a participation agreement, you will be able to skip this step during the onboarding process and simply contact your organization’s CRISP Point of Contact for access.The participation agreement is the uniform data sharing agreement signed by every organization that participates in CRISP. It ensures that everyone sharing data follows the same rules and regulations. Updating your NPP ensures that your practice does its part to inform patients about how CRISP is being used to deliver and coordinate care and informs them of the right to opt-out. Organizations must have CRISP Opt-Out Forms on-site to distribute to patients who ask for one. They must also maintain copies of the Patient Fact sheets in registration areas. New users without an agreement will be prompted to upload one during the onboarding process.\"),\n",
    "\tQuestionAnswer(question=\"How do I get started?\", answer=\"In addition, an organization must: 1.) Submit LabCorp/Quest Data Release Form if it wishes to make its results available in CRISP. 2.)Send a patient panel (all patients seen within the last 18 months) using DIRECT secure email to panelupload@crispdirect.org. This patient list will be used to audit your organization’s future activity to help ensure appropriate use. Here is a sample [Patient Panel](https://crisphealth.org/wp-content/uploads/2016/03/Sample-ENS-Patient-Panel.xlsx). 3.)In order to send us your panel, please email [support@crisphealth.org](panelupload@crispdirect.org) to request a DIRECT secure email address. Then, follow these [instructions](https://crisphealth.org/wp-content/uploads/2016/03/How-to-Upload-ENS-Participant-Panel.pdf)\"),\n",
    "\tQuestionAnswer(question=\"Who Contributes Health Information?\", answer=\"All 50 acute-care hospitals in Maryland and 7 acute care hospitals in DC are working with CRISP. To see which of these hospitals are currently providing clinical information, visit our Participating Providers page [here](https://crisphealth.org/about-crisp/connected-providers/).\")\n",
    "] * 100\n",
    "\n",
    "random.shuffle(data_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Total Number Of Samples 1900\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, random_split\n",
    "\n",
    "data_generator:DataGenerator = DataGenerator()\n",
    "\n",
    "generator = torch.Generator()\n",
    "\n",
    "generator.manual_seed(0)\n",
    "\n",
    "print(f\":: Total Number Of Samples {len(data_lines)}\")\n",
    "\n",
    "train_size = int(0.9 * len(data_lines))\n",
    "data_lines_processed = []\n",
    "for elem in data_lines:\n",
    "\tdata = data_generator.create_data_line(elem)\n",
    "\tdata_lines_processed.append(data)\n",
    "\n",
    "train_dataset_file, eval_dataset_file = random_split(list(data_lines_processed), [train_size, len(data_lines_processed) - train_size], generator=generator)\n",
    "\n",
    "train_file = f\"{model_output_dir}/train.txt\"\n",
    "eval_file = f\"{model_output_dir}/eval.txt\"\n",
    "\n",
    "with open(train_file, 'w', encoding=\"utf-8\") as train_out, open(eval_file, \"w\", encoding=\"utf-8\") as eval_out:\n",
    "        train_out.writelines([line + \"\\n\" for line in train_dataset_file])\n",
    "        eval_out.writelines([line + \"\\n\" for line in eval_dataset_file])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "('/workspaces/General/models/test-3\\\\tokenizer_config.json',\n '/workspaces/General/models/test-3\\\\special_tokens_map.json',\n '/workspaces/General/models/test-3\\\\vocab.json',\n '/workspaces/General/models/test-3\\\\merges.txt',\n '/workspaces/General/models/test-3\\\\added_tokens.json')"
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "from transformers.models.gpt2.modeling_gpt2 import GPT2LMHeadModel\n",
    "\n",
    "data_generator: DataGenerator = DataGenerator()\n",
    "\n",
    "special_tokens_dict: dict = data_generator.get_special_token_dict()\n",
    "\n",
    "tokenizer: GPT2Tokenizer = GPT2Tokenizer.from_pretrained(f\"gpt2{model_type}\")\n",
    "\n",
    "tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "model: GPT2LMHeadModel = GPT2LMHeadModel.from_pretrained(f\"gpt2{model_type}\")\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "model.save_pretrained(model_output_dir)\n",
    "\n",
    "tokenizer.save_pretrained(model_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/1710 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0e8c64e1a22c473097e38bc4288faa65"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "215d53090b334bac84ae6c1d571a2e7c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Running Epoch 0 of 3:   0%|          | 0/285 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f00db0a9787d4bbca175d59f36f8789c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Running Epoch 1 of 3:   0%|          | 0/285 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0d42028b65fd4676a02bfb2217e47ff7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "(7,\n {'global_step': [5, 7],\n  'perplexity': [tensor(inf), tensor(6.4822e+30)],\n  'eval_loss': [133.31558497094957, 70.94661173534695],\n  'train_loss': [77.20818328857422, 67.88777923583984]})"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from simpletransformers.config.model_args import LanguageModelingArgs\n",
    "from simpletransformers.language_modeling import LanguageModelingModel\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "args = {\n",
    "    \"overwrite_output_dir\": True,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"gradient_accumulation_steps\": 100,\n",
    "    \"dataset_type\": \"simple\",\n",
    "    \"sliding_window\": True,\n",
    "    \"max_seq_length\": 1024,\n",
    "\t\"mlm\": False,\n",
    "    \"evaluate_during_training\": True,\n",
    "    \"use_cached_eval_features\": True,\n",
    "    \"evaluate_during_training_verbose\": True,\n",
    "    \"save_optimizer_and_scheduler\": False,\n",
    "    \"save_eval_checkpoints\": False,\n",
    "    \"save_model_every_epoch\": True,\n",
    "    \"save_steps\": -1,\n",
    "    \"train_batch_size\":6,\n",
    "    \"num_train_epochs\":3,\n",
    "    \"output_dir\": f\"{model_output_dir}/\",\n",
    "\t\"best_model_dir\": f\"{model_output_dir}/best_model\"\n",
    "}\n",
    "with open(f\"{model_output_dir}/training_parameters.json\", 'w') as j:\n",
    "\tj.write(json.dumps(args, indent=4))\n",
    "\n",
    "model = LanguageModelingModel(\"gpt2\", model_output_dir, args=args)\n",
    "model.train_model(train_file=train_file, eval_file=eval_file, args=args, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[31m╭─\u001B[0m\u001B[31m──────────────────────────────\u001B[0m\u001B[31m \u001B[0m\u001B[1;31mTraceback \u001B[0m\u001B[1;2;31m(most recent call last)\u001B[0m\u001B[31m \u001B[0m\u001B[31m───────────────────────────────\u001B[0m\u001B[31m─╮\u001B[0m\n\u001B[31m│\u001B[0m in \u001B[92m<module>\u001B[0m                                                                                      \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 9 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[33m'\u001B[0m\u001B[33mtop_k\u001B[0m\u001B[33m'\u001B[0m: \u001B[94m80\u001B[0m                                                                         \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m10 \u001B[0m}                                                                                           \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m11 \u001B[0m                                                                                            \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m12 text_model_generator = LanguageGenerationModel(\u001B[33m\"\u001B[0m\u001B[33mgpt2\u001B[0m\u001B[33m\"\u001B[0m,  \u001B[33mf\u001B[0m\u001B[33m\"\u001B[0m\u001B[33m{\u001B[0mmodel_output_dir\u001B[33m}\u001B[0m\u001B[33m/best_model\u001B[0m\u001B[33m\"\u001B[0m    \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m13 \u001B[0m                                                                                            \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m14 \u001B[0mquestion = \u001B[33m\"\u001B[0m\u001B[33mHow do I Sign up?\u001B[0m\u001B[33m\"\u001B[0m                                                              \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m15 \u001B[0m                                                                                            \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[33mD:\\workspaces\\General\\venv\\lib\\site-packages\\simpletransformers\\language_generation\\language_gen\u001B[0m \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[33meration_model.py\u001B[0m:\u001B[94m147\u001B[0m in \u001B[92m__init__\u001B[0m                                                                 \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m144 \u001B[0m\u001B[2m│   │   │   \u001B[0m**kwargs,                                                                      \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m145 \u001B[0m\u001B[2m│   │   \u001B[0m)                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m146 \u001B[0m\u001B[2m│   │   \u001B[0m                                                                                   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m147 \u001B[2m│   │   \u001B[0m\u001B[96mself\u001B[0m.model.to(\u001B[96mself\u001B[0m.device)                                                         \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m148 \u001B[0m\u001B[2m│   \u001B[0m                                                                                       \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m149 \u001B[0m\u001B[2m│   \u001B[0m\u001B[94mdef\u001B[0m \u001B[92mgenerate\u001B[0m(\u001B[96mself\u001B[0m, prompt=\u001B[94mNone\u001B[0m, args=\u001B[94mNone\u001B[0m, verbose=\u001B[94mTrue\u001B[0m):                              \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m150 \u001B[0m                                                                                           \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[33mD:\\workspaces\\General\\venv\\lib\\site-packages\\transformers\\modeling_utils.py\u001B[0m:\u001B[94m1682\u001B[0m in \u001B[92mto\u001B[0m           \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1679 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[33m\"\u001B[0m\u001B[33m model has already been set to the correct devices and casted to the co\u001B[0m  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1680 \u001B[0m\u001B[2m│   │   │   \u001B[0m)                                                                             \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1681 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94melse\u001B[0m:                                                                             \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m1682 \u001B[2m│   │   │   \u001B[0m\u001B[94mreturn\u001B[0m \u001B[96msuper\u001B[0m().to(*args, **kwargs)                                            \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1683 \u001B[0m\u001B[2m│   \u001B[0m                                                                                      \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1684 \u001B[0m\u001B[2m│   \u001B[0m\u001B[94mdef\u001B[0m \u001B[92mhalf\u001B[0m(\u001B[96mself\u001B[0m, *args):                                                                \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1685 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[2m# Checks if the model has been loaded in 8-bit\u001B[0m                                    \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[33mD:\\workspaces\\General\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m:\u001B[94m989\u001B[0m in \u001B[92mto\u001B[0m                \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 986 \u001B[0m\u001B[2m│   │   │   │   │   │   │   \u001B[0mnon_blocking, memory_format=convert_to_format)                \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 987 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[94mreturn\u001B[0m t.to(device, dtype \u001B[94mif\u001B[0m t.is_floating_point() \u001B[95mor\u001B[0m t.is_complex() \u001B[94melse\u001B[0m \u001B[94mNo\u001B[0m  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 988 \u001B[0m\u001B[2m│   │   \u001B[0m                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m 989 \u001B[2m│   │   \u001B[0m\u001B[94mreturn\u001B[0m \u001B[96mself\u001B[0m._apply(convert)                                                       \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 990 \u001B[0m\u001B[2m│   \u001B[0m                                                                                      \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 991 \u001B[0m\u001B[2m│   \u001B[0m\u001B[94mdef\u001B[0m \u001B[92mregister_backward_hook\u001B[0m(                                                           \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 992 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[96mself\u001B[0m, hook: Callable[[\u001B[33m'\u001B[0m\u001B[33mModule\u001B[0m\u001B[33m'\u001B[0m, _grad_t, _grad_t], Union[\u001B[94mNone\u001B[0m, Tensor]]           \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[33mD:\\workspaces\\General\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m:\u001B[94m641\u001B[0m in \u001B[92m_apply\u001B[0m            \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 638 \u001B[0m\u001B[2m│   \u001B[0m                                                                                      \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 639 \u001B[0m\u001B[2m│   \u001B[0m\u001B[94mdef\u001B[0m \u001B[92m_apply\u001B[0m(\u001B[96mself\u001B[0m, fn):                                                                 \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 640 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mfor\u001B[0m module \u001B[95min\u001B[0m \u001B[96mself\u001B[0m.children():                                                    \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m 641 \u001B[2m│   │   │   \u001B[0mmodule._apply(fn)                                                             \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 642 \u001B[0m\u001B[2m│   │   \u001B[0m                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 643 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mdef\u001B[0m \u001B[92mcompute_should_use_set_data\u001B[0m(tensor, tensor_applied):                          \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 644 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[94mif\u001B[0m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[33mD:\\workspaces\\General\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m:\u001B[94m641\u001B[0m in \u001B[92m_apply\u001B[0m            \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 638 \u001B[0m\u001B[2m│   \u001B[0m                                                                                      \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 639 \u001B[0m\u001B[2m│   \u001B[0m\u001B[94mdef\u001B[0m \u001B[92m_apply\u001B[0m(\u001B[96mself\u001B[0m, fn):                                                                 \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 640 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mfor\u001B[0m module \u001B[95min\u001B[0m \u001B[96mself\u001B[0m.children():                                                    \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m 641 \u001B[2m│   │   │   \u001B[0mmodule._apply(fn)                                                             \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 642 \u001B[0m\u001B[2m│   │   \u001B[0m                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 643 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mdef\u001B[0m \u001B[92mcompute_should_use_set_data\u001B[0m(tensor, tensor_applied):                          \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 644 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[94mif\u001B[0m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[33mD:\\workspaces\\General\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m:\u001B[94m664\u001B[0m in \u001B[92m_apply\u001B[0m            \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 661 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[2m# track autograd history of `param_applied`, so we have to use\u001B[0m                \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 662 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[2m# `with torch.no_grad():`\u001B[0m                                                     \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 663 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[94mwith\u001B[0m torch.no_grad():                                                         \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m 664 \u001B[2m│   │   │   │   \u001B[0mparam_applied = fn(param)                                                 \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 665 \u001B[0m\u001B[2m│   │   │   \u001B[0mshould_use_set_data = compute_should_use_set_data(param, param_applied)       \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 666 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[94mif\u001B[0m should_use_set_data:                                                       \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 667 \u001B[0m\u001B[2m│   │   │   │   \u001B[0mparam.data = param_applied                                                \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[33mD:\\workspaces\\General\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m:\u001B[94m987\u001B[0m in \u001B[92mconvert\u001B[0m           \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 984 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[94mif\u001B[0m convert_to_format \u001B[95mis\u001B[0m \u001B[95mnot\u001B[0m \u001B[94mNone\u001B[0m \u001B[95mand\u001B[0m t.dim() \u001B[95min\u001B[0m (\u001B[94m4\u001B[0m, \u001B[94m5\u001B[0m):                       \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 985 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[94mreturn\u001B[0m t.to(device, dtype \u001B[94mif\u001B[0m t.is_floating_point() \u001B[95mor\u001B[0m t.is_complex() \u001B[94mels\u001B[0m  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 986 \u001B[0m\u001B[2m│   │   │   │   │   │   │   \u001B[0mnon_blocking, memory_format=convert_to_format)                \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m 987 \u001B[2m│   │   │   \u001B[0m\u001B[94mreturn\u001B[0m t.to(device, dtype \u001B[94mif\u001B[0m t.is_floating_point() \u001B[95mor\u001B[0m t.is_complex() \u001B[94melse\u001B[0m \u001B[94mNo\u001B[0m  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 988 \u001B[0m\u001B[2m│   │   \u001B[0m                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 989 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mreturn\u001B[0m \u001B[96mself\u001B[0m._apply(convert)                                                       \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 990 \u001B[0m                                                                                          \u001B[31m│\u001B[0m\n\u001B[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001B[0m\n\u001B[1;91mRuntimeError: \u001B[0mCUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be \nincorrect.\nFor debugging consider passing \u001B[33mCUDA_LAUNCH_BLOCKING\u001B[0m=\u001B[1;36m1\u001B[0m.\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9 │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">'top_k'</span>: <span style=\"color: #0000ff; text-decoration-color: #0000ff\">80</span>                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">10 </span>}                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">11 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>12 text_model_generator = LanguageGenerationModel(<span style=\"color: #808000; text-decoration-color: #808000\">\"gpt2\"</span>,  <span style=\"color: #808000; text-decoration-color: #808000\">f\"{</span>model_output_dir<span style=\"color: #808000; text-decoration-color: #808000\">}/best_model\"</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">13 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14 </span>question = <span style=\"color: #808000; text-decoration-color: #808000\">\"How do I Sign up?\"</span>                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">D:\\workspaces\\General\\venv\\lib\\site-packages\\simpletransformers\\language_generation\\language_gen</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">eration_model.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">147</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">144 │   │   │   </span>**kwargs,                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">145 │   │   </span>)                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">146 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>147 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.model.to(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.device)                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">148 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">149 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">generate</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, prompt=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>, args=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>, verbose=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>):                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">150 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">D:\\workspaces\\General\\venv\\lib\\site-packages\\transformers\\modeling_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1682</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">to</span>           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1679 │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\" model has already been set to the correct devices and casted to the co</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1680 │   │   │   </span>)                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1681 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1682 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">super</span>().to(*args, **kwargs)                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1683 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1684 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">half</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, *args):                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1685 │   │   # Checks if the model has been loaded in 8-bit</span>                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">D:\\workspaces\\General\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">989</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">to</span>                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 986 │   │   │   │   │   │   │   </span>non_blocking, memory_format=convert_to_format)                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 987 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> t.to(device, dtype <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> t.is_floating_point() <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> t.is_complex() <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">No</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 988 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 989 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._apply(convert)                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 990 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 991 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">register_backward_hook</span>(                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 992 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, hook: Callable[[<span style=\"color: #808000; text-decoration-color: #808000\">'Module'</span>, _grad_t, _grad_t], Union[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>, Tensor]]           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">D:\\workspaces\\General\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">641</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_apply</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 638 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 639 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_apply</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, fn):                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 640 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> module <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.children():                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 641 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>module._apply(fn)                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 642 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 643 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">compute_should_use_set_data</span>(tensor, tensor_applied):                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 644 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">D:\\workspaces\\General\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">641</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_apply</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 638 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 639 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_apply</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, fn):                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 640 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> module <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.children():                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 641 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>module._apply(fn)                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 642 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 643 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">compute_should_use_set_data</span>(tensor, tensor_applied):                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 644 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">D:\\workspaces\\General\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">664</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_apply</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 661 │   │   │   # track autograd history of `param_applied`, so we have to use</span>                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 662 │   │   │   # `with torch.no_grad():`</span>                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 663 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> torch.no_grad():                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 664 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>param_applied = fn(param)                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 665 │   │   │   </span>should_use_set_data = compute_should_use_set_data(param, param_applied)       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 666 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> should_use_set_data:                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 667 │   │   │   │   </span>param.data = param_applied                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">D:\\workspaces\\General\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">987</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">convert</span>           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 984 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> convert_to_format <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> t.dim() <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> (<span style=\"color: #0000ff; text-decoration-color: #0000ff\">4</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">5</span>):                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 985 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> t.to(device, dtype <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> t.is_floating_point() <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> t.is_complex() <span style=\"color: #0000ff; text-decoration-color: #0000ff\">els</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 986 │   │   │   │   │   │   │   </span>non_blocking, memory_format=convert_to_format)                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 987 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> t.to(device, dtype <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> t.is_floating_point() <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> t.is_complex() <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">No</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 988 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 989 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._apply(convert)                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 990 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">RuntimeError: </span>CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be \nincorrect.\nFor debugging consider passing <span style=\"color: #808000; text-decoration-color: #808000\">CUDA_LAUNCH_BLOCKING</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>.\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from simpletransformers.language_generation import LanguageGenerationModel, LanguageGenerationArgs\n",
    "\n",
    "args = {\n",
    "\t\t'max_length': 1024,\n",
    "\t\t'num_return_sequences': 1,\n",
    "\t\t'repetition_penalty': 1.01,\n",
    "\t\t'stop_token': '<|endoftext|>',\n",
    "\t\t'temperature': 0.8,\n",
    "\t\t'top_k': 80\n",
    "}\n",
    "\n",
    "text_model_generator = LanguageGenerationModel(\"gpt2\",  f\"{model_output_dir}/best_model\", args=args, use_cuda=True)\n",
    "\n",
    "question = \"How do I Sign up?\"\n",
    "\n",
    "prompt = f'<|startoftext|><|startofquestion|>{question}<|endofquestion|><|startofreply|>'\n",
    "\n",
    "result = \"It don't work\"\n",
    "for text in text_model_generator.generate(prompt=prompt, args=args, verbose=True):\n",
    "  result = text.replace(prompt, \"\").replace(\"<|endofreply|>\", \"\")\n",
    "\n",
    "pretty_response = f\"<h1>Prompt: {question}</h1><br/><h1>Rely:{result}</h1>\"\n",
    "\n",
    "print(f\"Prompt: {question}\")\n",
    "print(f\"Reply: {result}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
